{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cf7f7a-23de-4524-8d28-d4f2cc7265fc",
   "metadata": {},
   "source": [
    "<img src=\"../../../images/banners/ml-algorithms.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180b914-8b5b-4272-b30e-e7eb4864f60f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"intro_to_data_structures\"></a>\n",
    "# <img src=\"../../../images/logos/ml-logo.png\" width=\"23\"/> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8d041-386c-4d95-a2fa-44a2eabf6a69",
   "metadata": {},
   "source": [
    "## <img src=\"../../../images/logos/toc.png\" width=\"20\"/> Table of Contents\n",
    "* [Logistic Regression](#)\n",
    "* [Generative vs Discriminative Setting](#)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e13c0-660c-454b-8f14-b87ffe88402d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d280c7d-c275-4c8c-a640-bec3092cf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2d79f2-335e-4028-9ff2-d179f6c15b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X = np.hstack((np.ones((len(y), 1)), X))\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87aa64f-48b1-4dc8-83ed-ab9d7c3540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e698-476a-41ec-bf0f-09899f5885bb",
   "metadata": {},
   "source": [
    "### Building A Logistic Regression in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6e06ba-75dd-4e88-9d2f-f8346d3f2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(num_features)\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights)\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "            # Update weights and bias using gradient descent\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights)\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b332c7f6-ee21-4272-9768-5864313a37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LogisticRegression and fit the training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98b090c-3fab-4fd0-871f-5f05f17c7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62743fd-35ee-415a-a5bf-40d40b011d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6418d14-813a-4274-8037-b118626c1b50",
   "metadata": {},
   "source": [
    "### `sklearn` Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d753aed-f7b4-4240-a483-062a27f8b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119b0246-7b81-4e2d-8917-8f5703f369fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression and fit the training data\n",
    "model = SKLogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ab1d67-40a1-4f4a-9681-b978becb2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28911d0-5296-443c-8011-50c1ecbaa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e8e051-1ab9-47ae-af7d-0b5e716c695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c43dd0-8375-41fc-b842-86f0b9e57f65",
   "metadata": {},
   "source": [
    "## Generative vs Discriminative Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d38dcf-b392-445a-ae4c-c5a14b73a4ef",
   "metadata": {},
   "source": [
    "Discriminative and generative approaches are two different ways of tackling problems in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fc619-1e03-4af6-ab35-2230bbb2ce94",
   "metadata": {},
   "source": [
    "In simple terms, a discriminative approach focuses on learning the boundary or decision-making process between different classes or categories. It aims to find a direct mapping from input data to output labels. It learns the relationship between the input and output directly without explicitly modeling the underlying distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c8995-921d-4824-bafd-8b36f2dd15fd",
   "metadata": {},
   "source": [
    "<img src=\"../images/generative-vs-discriminative-models.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe906812-917c-44e0-a1cc-43696470ccc3",
   "metadata": {},
   "source": [
    "For example, let's say we have a dataset of images with cats and dogs, and we want to build a model that can classify new images as either cats or dogs. In a discriminative approach, the model would learn the features or patterns in the images that distinguish cats from dogs. It would then use these learned features to make predictions on new, unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bfbcf-3e08-48d5-a928-76cb38d6e2a8",
   "metadata": {},
   "source": [
    "On the other hand, a generative approach focuses on modeling the joint distribution of the input data and output labels. It aims to understand how the data is generated from different classes or categories. It learns the underlying distribution of the data and uses this knowledge to generate new data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea54acc-6d15-4ebd-af06-371cb94142bf",
   "metadata": {},
   "source": [
    "Using the same example, in a generative approach, the model would first learn the distribution of features or patterns for both cats and dogs separately. It would then use this information to generate new images that resemble either cats or dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fcf75-3abd-4dbc-94da-d1f3603fc1e7",
   "metadata": {},
   "source": [
    "<img src=\"../images/generative-vs-discriminative-models-2.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c11593-6eb0-4f11-9159-877096404458",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "- Discriminative approach: Learns the boundary or decision-making process directly between different classes. It focuses on the relationship between input and output without explicitly modeling the underlying distribution.\n",
    "- Generative approach: Models the joint distribution of the input data and output labels. It focuses on understanding how the data is generated from different classes and can generate new samples.\n",
    "- Both approaches have their advantages and are useful in different scenarios. Discriminative models are often simpler and can be more efficient for classification tasks. Generative models, on the other hand, can be useful when we want to understand the underlying structure of the data or generate new samples that resemble the given data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f81804-e451-4be4-84f0-21cf38b0a36c",
   "metadata": {},
   "source": [
    "> Note: When we say discriminative models are often simpler, we are referring to the fact that they directly learn the decision boundary between different classes or categories without explicitly modeling the underlying data distribution. This direct mapping from input to output makes the modeling task more focused and potentially easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316413d-597b-41a3-8e75-27e39a901da2",
   "metadata": {},
   "source": [
    "Here's a table summarizing the advantages and disadvantages of the discriminative and generative approaches in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f550e-414c-4e6f-8bd9-593d8d24495e",
   "metadata": {},
   "source": [
    "|                    | Generative Approach                               | Discriminative Approach                                          |\n",
    "|--------------------|--------------------------------------------------|------------------------------------------------------------------|\n",
    "| Advantages         | - **Data generation**: Ability to generate new data samples | - **Simplicity**: Direct mapping from input to output            |\n",
    "|                    | - **Handling missing data**: Can handle missing or incomplete data | - **Computational efficiency**: Fewer parameters                |\n",
    "|                    | - **Anomaly detection**: Can identify outliers or anomalies | - **Feature relevance**: Focus on discriminative features       |\n",
    "|                    | - **Data synthesis**: Can generate data that resembles the given distribution | - **Generalization**: Good at predicting on new data       |\n",
    "| Disadvantages      | - **Complexity**: More parameters and computational resources required | - **Limited information**: Ignores data distribution         |\n",
    "|                    | - **Overfitting risk**: Prone to overfitting if not enough data available | - **Data imbalance**: Sensitive to imbalanced data          |\n",
    "|                    | - **Computational cost**: More complex and computationally expensive | - **No data generation**: Cannot generate new data         |\n",
    "|                    | - **Interpretability**: More challenging to interpret and understand | - **Task-specific**: More suitable for classification tasks |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92377fd-cda8-46ab-a820-1c69c9cdbd53",
   "metadata": {},
   "source": [
    "<img src=\"../images/chatgpt.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cbc29-76cb-41ff-8a37-a65384ad16cb",
   "metadata": {},
   "source": [
    "It's interesting to know that ChatGPT is a generative model. It belongs to a family of models called generative pre-trained transformers (GPT), which are designed to generate text based on the patterns and structures it has learned from the training data. ChatGPT generates responses to input based on the context and tries to produce coherent and relevant text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
