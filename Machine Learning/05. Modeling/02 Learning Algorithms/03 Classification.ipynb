{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cf7f7a-23de-4524-8d28-d4f2cc7265fc",
   "metadata": {},
   "source": [
    "<img src=\"../../../images/banners/ml-algorithms.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180b914-8b5b-4272-b30e-e7eb4864f60f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"intro_to_data_structures\"></a>\n",
    "# <img src=\"../../../images/logos/ml-logo.png\" width=\"23\"/> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8d041-386c-4d95-a2fa-44a2eabf6a69",
   "metadata": {},
   "source": [
    "## <img src=\"../../../images/logos/toc.png\" width=\"20\"/> Table of Contents\n",
    "* [Logistic Regression](#)\n",
    "* [Generative vs Discriminative Setting](#)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e13c0-660c-454b-8f14-b87ffe88402d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d280c7d-c275-4c8c-a640-bec3092cf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2d79f2-335e-4028-9ff2-d179f6c15b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X = np.hstack((np.ones((len(y), 1)), X))\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87aa64f-48b1-4dc8-83ed-ab9d7c3540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e698-476a-41ec-bf0f-09899f5885bb",
   "metadata": {},
   "source": [
    "### Building A Logistic Regression in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6e06ba-75dd-4e88-9d2f-f8346d3f2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(num_features)\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights)\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "            # Update weights and bias using gradient descent\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights)\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b332c7f6-ee21-4272-9768-5864313a37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of LogisticRegression and fit the training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98b090c-3fab-4fd0-871f-5f05f17c7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62743fd-35ee-415a-a5bf-40d40b011d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6418d14-813a-4274-8037-b118626c1b50",
   "metadata": {},
   "source": [
    "### `sklearn` Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d753aed-f7b4-4240-a483-062a27f8b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119b0246-7b81-4e2d-8917-8f5703f369fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression and fit the training data\n",
    "model = SKLogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ab1d67-40a1-4f4a-9681-b978becb2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28911d0-5296-443c-8011-50c1ecbaa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e8e051-1ab9-47ae-af7d-0b5e716c695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c43dd0-8375-41fc-b842-86f0b9e57f65",
   "metadata": {},
   "source": [
    "## Generative vs Discriminative Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d38dcf-b392-445a-ae4c-c5a14b73a4ef",
   "metadata": {},
   "source": [
    "Discriminative and generative approaches are two different ways of tackling problems in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552fc619-1e03-4af6-ab35-2230bbb2ce94",
   "metadata": {},
   "source": [
    "In simple terms, a discriminative approach focuses on learning the boundary or decision-making process between different classes or categories. It aims to find a direct mapping from input data to output labels. It learns the relationship between the input and output directly without explicitly modeling the underlying distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c8995-921d-4824-bafd-8b36f2dd15fd",
   "metadata": {},
   "source": [
    "<img src=\"../images/generative-vs-discriminative-models.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe906812-917c-44e0-a1cc-43696470ccc3",
   "metadata": {},
   "source": [
    "For example, let's say we have a dataset of images with cats and dogs, and we want to build a model that can classify new images as either cats or dogs. In a discriminative approach, the model would learn the features or patterns in the images that distinguish cats from dogs. It would then use these learned features to make predictions on new, unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bfbcf-3e08-48d5-a928-76cb38d6e2a8",
   "metadata": {},
   "source": [
    "On the other hand, a generative approach focuses on modeling the joint distribution of the input data and output labels. It aims to understand how the data is generated from different classes or categories. It learns the underlying distribution of the data and uses this knowledge to generate new data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea54acc-6d15-4ebd-af06-371cb94142bf",
   "metadata": {},
   "source": [
    "Using the same example, in a generative approach, the model would first learn the distribution of features or patterns for both cats and dogs separately. It would then use this information to generate new images that resemble either cats or dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fcf75-3abd-4dbc-94da-d1f3603fc1e7",
   "metadata": {},
   "source": [
    "<img src=\"../images/generative-vs-discriminative-models-2.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c11593-6eb0-4f11-9159-877096404458",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "- Discriminative approach: Learns the boundary or decision-making process directly between different classes. It focuses on the relationship between input and output without explicitly modeling the underlying distribution.\n",
    "- Generative approach: Models the joint distribution of the input data and output labels. It focuses on understanding how the data is generated from different classes and can generate new samples.\n",
    "- Both approaches have their advantages and are useful in different scenarios. Discriminative models are often simpler and can be more efficient for classification tasks. Generative models, on the other hand, can be useful when we want to understand the underlying structure of the data or generate new samples that resemble the given data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f81804-e451-4be4-84f0-21cf38b0a36c",
   "metadata": {},
   "source": [
    "> Note: When we say discriminative models are often simpler, we are referring to the fact that they directly learn the decision boundary between different classes or categories without explicitly modeling the underlying data distribution. This direct mapping from input to output makes the modeling task more focused and potentially easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316413d-597b-41a3-8e75-27e39a901da2",
   "metadata": {},
   "source": [
    "Here's a table summarizing the advantages and disadvantages of the discriminative and generative approaches in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f550e-414c-4e6f-8bd9-593d8d24495e",
   "metadata": {},
   "source": [
    "|                    | Generative Approach                               | Discriminative Approach                                          |\n",
    "|--------------------|--------------------------------------------------|------------------------------------------------------------------|\n",
    "| Advantages         | - **Data generation**: Ability to generate new data samples | - **Simplicity**: Direct mapping from input to output            |\n",
    "|                    | - **Handling missing data**: Can handle missing or incomplete data | - **Computational efficiency**: Fewer parameters                |\n",
    "|                    | - **Anomaly detection**: Can identify outliers or anomalies | - **Feature relevance**: Focus on discriminative features       |\n",
    "|                    | - **Data synthesis**: Can generate data that resembles the given distribution | - **Generalization**: Good at predicting on new data       |\n",
    "| Disadvantages      | - **Complexity**: More parameters and computational resources required | - **Limited information**: Ignores data distribution         |\n",
    "|                    | - **Overfitting risk**: Prone to overfitting if not enough data available | - **Data imbalance**: Sensitive to imbalanced data          |\n",
    "|                    | - **Computational cost**: More complex and computationally expensive | - **No data generation**: Cannot generate new data         |\n",
    "|                    | - **Interpretability**: More challenging to interpret and understand | - **Task-specific**: More suitable for classification tasks |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92377fd-cda8-46ab-a820-1c69c9cdbd53",
   "metadata": {},
   "source": [
    "<img src=\"../images/chatgpt.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cbc29-76cb-41ff-8a37-a65384ad16cb",
   "metadata": {},
   "source": [
    "It's interesting to know that ChatGPT is a generative model. It belongs to a family of models called generative pre-trained transformers (GPT), which are designed to generate text based on the patterns and structures it has learned from the training data. ChatGPT generates responses to input based on the context and tries to produce coherent and relevant text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f6e11-1c36-4a24-8191-08b8da50ace2",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2ba2e-0deb-4a89-a884-874967fcad74",
   "metadata": {},
   "source": [
    "<img src=\"../images/nb-theory.webp\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb58d5-6436-448b-bfc4-8f2490fdcf26",
   "metadata": {},
   "source": [
    "\n",
    "Naive Bayes classification is a simple yet powerful machine learning algorithm used for solving classification problems. It is based on Bayes' theorem and assumes that all features are independent of each other, hence the \"naive\" assumption. This algorithm calculates the probability of a given instance belonging to a particular class by considering the probabilities of each feature occurring in that class. By leveraging these probabilities, Naive Bayes can predict the class label of new instances with remarkable speed and efficiency. It is widely used in various domains, such as spam filtering, sentiment analysis, and document categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4121ca0-3c0a-4267-8c2d-420d01ebeeea",
   "metadata": {},
   "source": [
    "<img src=\"../images/nb-clf.webp\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b0e82-2d7f-4da0-954c-93195fb78e1b",
   "metadata": {},
   "source": [
    "Naive Bayes classification is highly effective in spam filtering. It analyzes the content and attributes of emails, learning the probability distributions of words and patterns in spam and non-spam emails. By calculating the likelihood of an email being spam or non-spam based on these probabilities, Naive Bayes accurately classifies incoming emails and helps filter out unwanted spam messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27912a53-1dc2-4164-a43a-08529105c9e5",
   "metadata": {},
   "source": [
    "<img src=\"../images/nb-spam.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195affd-3ba4-4080-9da9-a8360425b07f",
   "metadata": {},
   "source": [
    "- <img src=\"../../../images/logos/youtube.png\" width=\"15\"/> See [Naive Bayes, Clearly Explained!!!](https://www.youtube.com/watch?v=O2L2Uv9pdDA)\n",
    "- <img src=\"../../../images/logos/youtube.png\" width=\"15\"/> [Gaussian Naive Bayes, Clearly Explained!!!](https://www.youtube.com/watch?v=H3EjCKtlVog)\n",
    "- <img src=\"../../../images/logos/doc.png\" width=\"14\"/> [The Naive Bayes Model](http://www.cs.columbia.edu/~mcollins/em.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d8dc6-bf7b-4dc6-a7dc-66826c424a1b",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a412bd84-fea5-46ef-baf4-95e697595ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c49b1aa-9381-4341-927a-6cacc208ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spam dataset (you can replace this with your own dataset)\n",
    "data = pd.read_csv('./sms_spam_data/spam.txt', delimiter='\\t', header=None, names=['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a45a87d1-8208-45ca-a6de-8b4ef92c93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (email content) and labels (spam or not)\n",
    "X = data['text']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd0852d1-e78b-4da8-9425-c17ff76772bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b68e3bb-ffe5-4bf4-baf3-68a05b7d1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the email content into numerical feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d680a36a-eaee-411e-bb56-18ca0139b59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb93c99b-2b12-4f04-b376-c29d0082834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000pes  008704050406  0089  0121  01223585236  01223585334  02  \\\n",
       "0   0    0       0             0     0     0            0            0   0   \n",
       "1   0    0       0             0     0     0            0            0   0   \n",
       "2   0    0       0             0     0     0            0            0   0   \n",
       "3   0    0       0             0     0     0            0            0   0   \n",
       "4   0    0       0             0     0     0            0            0   0   \n",
       "5   0    0       0             0     0     0            0            0   0   \n",
       "6   0    0       0             0     0     0            0            0   0   \n",
       "7   0    1       0             0     0     0            0            0   1   \n",
       "8   0    0       0             0     0     0            0            0   0   \n",
       "9   0    0       0             0     0     0            0            0   0   \n",
       "\n",
       "   0207  ...  zeros  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada  èn  ú1  \n",
       "0     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "1     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "2     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "3     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "4     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "5     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "6     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "7     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "8     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "9     0  ...      0      0       0    0          0     0     0      0   0   0  \n",
       "\n",
       "[10 rows x 7702 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    X_train.todense(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c419f-c24f-4838-9942-034586d91bca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `sklearn` Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd0ee8db-2184-49ec-acbe-93a72319c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e3bcf0d-3233-4646-8ca2-6faffc6ce8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce570508-13b8-4e2d-af89-1543df8a7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd90563d-e230-4714-8ce8-4aa48c9a536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cdbf1c-9a5f-4815-b58c-ce3376dbb367",
   "metadata": {},
   "source": [
    "### Building Gaussian Naive Bayes from Scratch with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fc57ff-dd24-4f33-a6e2-93c6eb5dad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1495e382-bf73-4fd3-9673-1b071d4d1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa13daa-9c56-4175-af8f-1d85353d0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd4784c-a02b-4db3-ba47-255d3f1a5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNBClassifier:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.priors = np.zeros(self.num_classes)\n",
    "        self.means = np.zeros((self.num_classes, X.shape[1]))\n",
    "        self.variances = np.zeros((self.num_classes, X.shape[1]))\n",
    "\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.priors[i] = X_c.shape[0] / X.shape[0]\n",
    "            self.means[i] = X_c.mean(axis=0)\n",
    "            self.variances[i] = X_c.var(axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        posteriors = np.zeros((X.shape[0], self.num_classes))\n",
    "\n",
    "        for i, c in enumerate(self.classes):\n",
    "            prior = np.log(self.priors[i])\n",
    "            posterior = np.sum(np.log(self._gaussian_pdf(X, self.means[i], self.variances[i])), axis=1)\n",
    "            posteriors[:, i] = prior + posterior\n",
    "\n",
    "        return self.classes[np.argmax(posteriors, axis=1)]\n",
    "\n",
    "    def _gaussian_pdf(self, X, mean, variance):\n",
    "        return (1 / np.sqrt(2 * np.pi * variance)) * np.exp(-((X - mean) ** 2) / (2 * variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a97c86-1c79-464e-ac3d-a45159809fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "classifier = GaussianNBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe5513f-a8ea-45a0-8940-7adb45d903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5160234a-fe06-4bdd-b97f-c8e2f19c5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa947c5-3fe5-49f2-a4bb-9adf794f0dfd",
   "metadata": {},
   "source": [
    "### `sklearn` Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b3ec3b-84a2-463f-bd58-f0c1e0973fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee13b9b-5343-4e0d-84e4-1cbf4588ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "579abf59-04fa-48bd-9b9b-ea09b1fbe095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
